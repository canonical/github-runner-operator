08:55:57 INFO IP Address to use as the fake jobmanager: 10.145.216.110
08:55:58 WARNING unexpected facade SSHServer received from the controller
08:55:58 INFO Adding model github-pr-196a7-lxd:test-jobmanager-reactive-jaog on cloud localhost
08:55:58 WARNING unexpected facade SSHServer received from the controller
08:55:58 WARNING unexpected facade SSHSession received from the controller
08:55:58 WARNING unexpected facade SSHTunneler received from the controller
08:55:58 WARNING unexpected facade SSHServer received from the controller
08:55:59 INFO Deploying ch:amd64/jammy/mongodb-224
08:56:01 INFO Deploying ch:amd64/jammy/github-runner-image-builder-100
08:56:20 INFO Deploying local:jammy/github-runner-0
08:56:20 INFO Waiting for model:
  test-qh11xhus/0 [allocating] waiting: waiting for machine
  github-runner-image-builder-qh11xhus/0 [allocating] waiting: waiting for machine
08:56:50 INFO Waiting for model:
  test-qh11xhus/0 [allocating] waiting: waiting for machine
  github-runner-image-builder-qh11xhus/0 [allocating] waiting: waiting for machine
08:57:21 INFO Waiting for model:
  test-qh11xhus/0 [allocating] waiting: agent initialising
  github-runner-image-builder-qh11xhus/0 [allocating] waiting: waiting for machine
08:57:51 INFO Waiting for model:
  test-qh11xhus/0 [executing] maintenance: installing charm software
  github-runner-image-builder-qh11xhus/0 [allocating] waiting: waiting for machine
08:58:21 INFO Waiting for model:
  test-qh11xhus/0 [executing] blocked: Please provide image integration.
  github-runner-image-builder-qh11xhus/0 [executing] maintenance: Setting up Builder.
08:58:51 INFO Waiting for model:
  test-qh11xhus/0 [idle] blocked: Please provide image integration.
  github-runner-image-builder-qh11xhus/0 [executing] maintenance: Setting up Builder.
08:59:21 INFO Waiting for model:
  test-qh11xhus/0 [idle] blocked: Please provide image integration.
  github-runner-image-builder-qh11xhus/0 [executing] maintenance: Setting up Builder.
08:59:51 INFO Waiting for model:
  test-qh11xhus/0 [idle] blocked: Please provide image integration.
  github-runner-image-builder-qh11xhus/0 [executing] maintenance: Setting up Builder.
09:00:21 INFO Waiting for model:
  test-qh11xhus/0 [idle] blocked: Please provide image integration.
  github-runner-image-builder-qh11xhus/0 [executing] maintenance: Setting up Builder.
09:00:52 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] blocked: image integration required.
09:01:22 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:01:52 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:02:23 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:02:53 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:03:23 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:03:53 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:04:24 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:04:54 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:05:24 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:05:55 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:06:25 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:06:55 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:07:26 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:07:56 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:08:27 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:08:57 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:09:27 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:09:58 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:10:28 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:10:59 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:11:29 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:12:00 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:12:30 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:13:00 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:13:31 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:14:01 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:14:31 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:15:02 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:15:32 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:16:02 INFO Waiting for model:
  test-qh11xhus/0 [idle] waiting: Waiting for image over integration.
  github-runner-image-builder-qh11xhus/0 [executing] active: Building image.
09:16:33 INFO Waiting for model:
  test-qh11xhus/0 [executing] maintenance: Update image for runners
  github-runner-image-builder-qh11xhus/0 [idle] active: 
09:17:03 INFO Waiting for model:
  test-qh11xhus/0 [idle] active: 
09:17:07 INFO Waiting for model:
  test-qh11xhus/0 [idle] active: 
09:17:22 INFO Waiting for model:
  test-qh11xhus/0 [idle] active: 
09:17:53 INFO Waiting for model:
  test-qh11xhus/0 [idle] active: 
09:18:08 INFO Current reconcile ID: 869764b6-c834-4646-aaa5-2db690731232
09:19:09 INFO Current reconcile ID: 869764b6-c834-4646-aaa5-2db690731232
09:20:10 INFO Current reconcile ID: 8a49c65d-bc6a-421c-942f-0b4c81e3585e
09:20:10 INFO cli: juju integrate --model github-pr-196a7-lxd:test-jobmanager-reactive-jaog test-qh11xhus:mongodb mongodb:database
09:20:11 INFO wait: status changed:
+ .model.name = 'test-jobmanager-reactive-jaog'
+ .model.type = 'iaas'
+ .model.controller = 'github-pr-196a7-lxd'
+ .model.cloud = 'localhost'
+ .model.version = '3.6.8'
+ .model.region = 'localhost'
+ .model.model_status.current = 'available'
+ .machines['0'].juju_status.current = 'started'
+ .machines['0'].juju_status.version = '3.6.8'
+ .machines['0'].hostname = 'juju-3e1944-0'
+ .machines['0'].dns_name = '10.5.15.77'
+ .machines['0'].ip_addresses[0] = '10.5.15.77'
+ .machines['0'].instance_id = 'juju-3e1944-0'
+ .machines['0'].machine_status.current = 'running'
+ .machines['0'].machine_status.message = 'Running'
+ .machines['0'].modification_status.current = 'applied'
+ .machines['0'].base.name = 'ubuntu'
+ .machines['0'].base.channel = '22.04'
+ .machines['0'].network_interfaces['eth0'].ip_addresses[0] = '10.5.15.77'
+ .machines['0'].network_interfaces['eth0'].mac_address = '00:16:3e:48:98:bd'
+ .machines['0'].network_interfaces['eth0'].is_up = True
+ .machines['0'].network_interfaces['eth0'].gateway = '10.5.15.1'
+ .machines['0'].network_interfaces['eth0'].space = 'alpha'
+ .machines['0'].constraints = 'arch=amd64'
+ .machines['0'].hardware = 'arch=amd64 cores=0 mem=0M virt-type=container'
+ .machines['1'].juju_status.current = 'started'
+ .machines['1'].juju_status.version = '3.6.8'
+ .machines['1'].hostname = 'juju-3e1944-1'
+ .machines['1'].dns_name = '10.5.15.239'
+ .machines['1'].ip_addresses[0] = '10.5.15.239'
+ .machines['1'].instance_id = 'juju-3e1944-1'
+ .machines['1'].machine_status.current = 'running'
+ .machines['1'].machine_status.message = 'Running'
+ .machines['1'].modification_status.current = 'applied'
+ .machines['1'].base.name = 'ubuntu'
+ .machines['1'].base.channel = '22.04'
+ .machines['1'].network_interfaces['eth0'].ip_addresses[0] = '10.5.15.239'
+ .machines['1'].network_interfaces['eth0'].mac_address = '00:16:3e:57:41:97'
+ .machines['1'].network_interfaces['eth0'].is_up = True
+ .machines['1'].network_interfaces['eth0'].gateway = '10.5.15.1'
+ .machines['1'].network_interfaces['eth0'].space = 'alpha'
+ .machines['1'].constraints = 'arch=amd64'
+ .machines['1'].hardware = 'arch=amd64 cores=0 mem=0M virt-type=container'
+ .machines['2'].juju_status.current = 'started'
+ .machines['2'].juju_status.version = '3.6.8'
+ .machines['2'].hostname = 'juju-3e1944-2'
+ .machines['2'].dns_name = '10.5.15.133'
+ .machines['2'].ip_addresses[0] = '10.5.15.133'
+ .machines['2'].instance_id = 'juju-3e1944-2'
+ .machines['2'].machine_status.current = 'running'
+ .machines['2'].machine_status.message = 'Running'
+ .machines['2'].modification_status.current = 'applied'
+ .machines['2'].base.name = 'ubuntu'
+ .machines['2'].base.channel = '22.04'
+ .machines['2'].network_interfaces['eth0'].ip_addresses[0] = '10.5.15.133'
+ .machines['2'].network_interfaces['eth0'].mac_address = '00:16:3e:63:f2:c2'
+ .machines['2'].network_interfaces['eth0'].is_up = True
+ .machines['2'].network_interfaces['eth0'].gateway = '10.5.15.1'
+ .machines['2'].network_interfaces['eth0'].space = 'alpha'
+ .machines['2'].constraints = 'arch=amd64 mem=2048M root-disk=51200M'
+ .machines['2'].hardware = 'arch=amd64 cores=0 mem=2048M virt-type=container'
+ .apps['github-runner-image-builder-qh11xhus'].charm = 'github-runner-image-builder'
+ .apps['github-runner-image-builder-qh11xhus'].charm_origin = 'charmhub'
+ .apps['github-runner-image-builder-qh11xhus'].charm_name = 'github-runner-image-builder'
+ .apps['github-runner-image-builder-qh11xhus'].charm_rev = 100
+ .apps['github-runner-image-builder-qh11xhus'].exposed = False
+ .apps['github-runner-image-builder-qh11xhus'].base.name = 'ubuntu'
+ .apps['github-runner-image-builder-qh11xhus'].base.channel = '22.04'
+ .apps['github-runner-image-builder-qh11xhus'].charm_channel = 'latest/edge'
+ .apps['github-runner-image-builder-qh11xhus'].app_status.current = 'active'
+ .apps['github-runner-image-builder-qh11xhus'].relations['image'][0].related_app = 'test-qh11xhus'
+ .apps['github-runner-image-builder-qh11xhus'].relations['image'][0].interface = 'github_runner_image_v0'
+ .apps['github-runner-image-builder-qh11xhus'].relations['image'][0].scope = 'global'
+ .apps['github-runner-image-builder-qh11xhus'].units['github-runner-image-builder-qh11xhus/0'].workload_status.current = 'active'
+ .apps['github-runner-image-builder-qh11xhus'].units['github-runner-image-builder-qh11xhus/0'].juju_status.current = 'idle'
+ .apps['github-runner-image-builder-qh11xhus'].units['github-runner-image-builder-qh11xhus/0'].juju_status.version = '3.6.8'
+ .apps['github-runner-image-builder-qh11xhus'].units['github-runner-image-builder-qh11xhus/0'].leader = True
+ .apps['github-runner-image-builder-qh11xhus'].units['github-runner-image-builder-qh11xhus/0'].machine = '1'
+ .apps['github-runner-image-builder-qh11xhus'].units['github-runner-image-builder-qh11xhus/0'].public_address = '10.5.15.239'
+ .apps['github-runner-image-builder-qh11xhus'].endpoint_bindings[''] = 'alpha'
+ .apps['github-runner-image-builder-qh11xhus'].endpoint_bindings['cos-agent'] = 'alpha'
+ .apps['github-runner-image-builder-qh11xhus'].endpoint_bindings['image'] = 'alpha'
+ .apps['mongodb'].charm = 'mongodb'
+ .apps['mongodb'].charm_origin = 'charmhub'
+ .apps['mongodb'].charm_name = 'mongodb'
+ .apps['mongodb'].charm_rev = 224
+ .apps['mongodb'].exposed = False
+ .apps['mongodb'].base.name = 'ubuntu'
+ .apps['mongodb'].base.channel = '22.04'
+ .apps['mongodb'].charm_channel = '6/edge'
+ .apps['mongodb'].app_status.current = 'active'
+ .apps['mongodb'].relations['database'][0].related_app = 'test-qh11xhus'
+ .apps['mongodb'].relations['database'][0].interface = 'mongodb_client'
+ .apps['mongodb'].relations['database'][0].scope = 'global'
+ .apps['mongodb'].relations['database-peers'][0].related_app = 'mongodb'
+ .apps['mongodb'].relations['database-peers'][0].interface = 'mongodb-peers'
+ .apps['mongodb'].relations['database-peers'][0].scope = 'global'
+ .apps['mongodb'].relations['ldap-peers'][0].related_app = 'mongodb'
+ .apps['mongodb'].relations['ldap-peers'][0].interface = 'ldap-peers'
+ .apps['mongodb'].relations['ldap-peers'][0].scope = 'global'
+ .apps['mongodb'].relations['status-peers'][0].related_app = 'mongodb'
+ .apps['mongodb'].relations['status-peers'][0].interface = 'status-peers'
+ .apps['mongodb'].relations['status-peers'][0].scope = 'global'
+ .apps['mongodb'].relations['upgrade-version-a'][0].related_app = 'mongodb'
+ .apps['mongodb'].relations['upgrade-version-a'][0].interface = 'upgrade'
+ .apps['mongodb'].relations['upgrade-version-a'][0].scope = 'global'
+ .apps['mongodb'].units['mongodb/0'].workload_status.current = 'active'
+ .apps['mongodb'].units['mongodb/0'].workload_status.message = 'Primary.'
+ .apps['mongodb'].units['mongodb/0'].juju_status.current = 'executing'
+ .apps['mongodb'].units['mongodb/0'].juju_status.message = 'running database-relation-created hook'
+ .apps['mongodb'].units['mongodb/0'].juju_status.version = '3.6.8'
+ .apps['mongodb'].units['mongodb/0'].leader = True
+ .apps['mongodb'].units['mongodb/0'].machine = '0'
+ .apps['mongodb'].units['mongodb/0'].open_ports[0] = '27017/tcp'
+ .apps['mongodb'].units['mongodb/0'].public_address = '10.5.15.77'
+ .apps['mongodb'].version = '6.0.24'
+ .apps['mongodb'].endpoint_bindings[''] = 'alpha'
+ .apps['mongodb'].endpoint_bindings['certificates'] = 'alpha'
+ .apps['mongodb'].endpoint_bindings['cluster'] = 'alpha'
+ .apps['mongodb'].endpoint_bindings['config-server'] = 'alpha'
+ .apps['mongodb'].endpoint_bindings['cos-agent'] = 'alpha'
+ .apps['mongodb'].endpoint_bindings['database'] = 'alpha'
+ .apps['mongodb'].endpoint_bindings['database-peers'] = 'alpha'
+ .apps['mongodb'].endpoint_bindings['ldap'] = 'alpha'
+ .apps['mongodb'].endpoint_bindings['ldap-certificate-transfer'] = 'alpha'
+ .apps['mongodb'].endpoint_bindings['ldap-peers'] = 'alpha'
+ .apps['mongodb'].endpoint_bindings['s3-credentials'] = 'alpha'
+ .apps['mongodb'].endpoint_bindings['sharding'] = 'alpha'
+ .apps['mongodb'].endpoint_bindings['status-peers'] = 'alpha'
+ .apps['mongodb'].endpoint_bindings['upgrade-version-a'] = 'alpha'
+ .apps['test-qh11xhus'].charm = 'local:jammy/github-runner-0'
+ .apps['test-qh11xhus'].charm_origin = 'local'
+ .apps['test-qh11xhus'].charm_name = 'github-runner'
+ .apps['test-qh11xhus'].charm_rev = 0
+ .apps['test-qh11xhus'].exposed = False
+ .apps['test-qh11xhus'].base.name = 'ubuntu'
+ .apps['test-qh11xhus'].base.channel = '22.04'
+ .apps['test-qh11xhus'].app_status.current = 'active'
+ .apps['test-qh11xhus'].relations['image'][0].related_app = 'github-runner-image-builder-qh11xhus'
+ .apps['test-qh11xhus'].relations['image'][0].interface = 'github_runner_image_v0'
+ .apps['test-qh11xhus'].relations['image'][0].scope = 'global'
+ .apps['test-qh11xhus'].relations['mongodb'][0].related_app = 'mongodb'
+ .apps['test-qh11xhus'].relations['mongodb'][0].interface = 'mongodb_client'
+ .apps['test-qh11xhus'].relations['mongodb'][0].scope = 'global'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].workload_status.current = 'active'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.current = 'executing'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.message = 'running mongodb-relation-created hook'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.version = '3.6.8'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].leader = True
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].machine = '2'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].public_address = '10.5.15.133'
+ .apps['test-qh11xhus'].endpoint_bindings[''] = 'alpha'
+ .apps['test-qh11xhus'].endpoint_bindings['cos-agent'] = 'alpha'
+ .apps['test-qh11xhus'].endpoint_bindings['debug-ssh'] = 'alpha'
+ .apps['test-qh11xhus'].endpoint_bindings['image'] = 'alpha'
+ .apps['test-qh11xhus'].endpoint_bindings['mongodb'] = 'alpha'
+ .storage.storage['mongodb/0'].kind = 'filesystem'
+ .storage.storage['mongodb/0'].status.current = 'attached'
+ .storage.storage['mongodb/0'].persistent = False
+ .storage.storage['mongodb/0'].life = 'alive'
+ .storage.storage['mongodb/0'].attachments.units['mongodb/0'].machine = '0'
+ .storage.storage['mongodb/0'].attachments.units['mongodb/0'].location = '/var/snap/charmed-mongodb/common'
+ .storage.storage['mongodb/0'].attachments.units['mongodb/0'].life = 'alive'
+ .storage.storage['runner/1'].kind = 'filesystem'
+ .storage.storage['runner/1'].status.current = 'attached'
+ .storage.storage['runner/1'].persistent = False
+ .storage.storage['runner/1'].life = 'alive'
+ .storage.storage['runner/1'].attachments.units['test-qh11xhus/0'].machine = '2'
+ .storage.storage['runner/1'].attachments.units['test-qh11xhus/0'].location = '/storage/juju'
+ .storage.storage['runner/1'].attachments.units['test-qh11xhus/0'].life = 'alive'
+ .storage.filesystems['0/0'].size = 49433
+ .storage.filesystems['0/0'].provider_id = '0/0'
+ .storage.filesystems['0/0'].storage = 'mongodb/0'
+ .storage.filesystems['0/0'].attachments.machines['0'].mount_point = '/var/snap/charmed-mongodb/common'
+ .storage.filesystems['0/0'].attachments.machines['0'].read_only = False
+ .storage.filesystems['0/0'].attachments.machines['0'].life = 'alive'
+ .storage.filesystems['0/0'].attachments.units['mongodb/0'].machine = '0'
+ .storage.filesystems['0/0'].attachments.units['mongodb/0'].location = '/var/snap/charmed-mongodb/common'
+ .storage.filesystems['0/0'].attachments.units['mongodb/0'].life = 'alive'
+ .storage.filesystems['0/0'].pool = 'rootfs'
+ .storage.filesystems['0/0'].life = 'alive'
+ .storage.filesystems['0/0'].status.current = 'attached'
+ .storage.filesystems['2/1'].size = 49433
+ .storage.filesystems['2/1'].provider_id = '2/1'
+ .storage.filesystems['2/1'].storage = 'runner/1'
+ .storage.filesystems['2/1'].attachments.machines['2'].mount_point = '/storage/juju'
+ .storage.filesystems['2/1'].attachments.machines['2'].read_only = False
+ .storage.filesystems['2/1'].attachments.machines['2'].life = 'alive'
+ .storage.filesystems['2/1'].attachments.units['test-qh11xhus/0'].machine = '2'
+ .storage.filesystems['2/1'].attachments.units['test-qh11xhus/0'].location = '/storage/juju'
+ .storage.filesystems['2/1'].attachments.units['test-qh11xhus/0'].life = 'alive'
+ .storage.filesystems['2/1'].pool = 'rootfs'
+ .storage.filesystems['2/1'].life = 'alive'
+ .storage.filesystems['2/1'].status.current = 'attached'
09:20:12 INFO wait: status changed:
- .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.message = 'running mongodb-relation-created hook'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.message = 'running mongodb-relation-joined hook for mongodb/0'
09:20:13 INFO wait: status changed:
- .apps['mongodb'].units['mongodb/0'].juju_status.message = 'running database-relation-created hook'
+ .apps['mongodb'].units['mongodb/0'].juju_status.message = 'running database-relation-changed hook'
09:20:14 INFO wait: status changed:
- .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.message = 'running mongodb-relation-joined hook for mongodb/0'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.message = 'running mongodb-relation-changed hook for mongodb/0'
09:20:16 INFO wait: status changed:
- .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.current = 'executing'
- .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.message = 'running mongodb-relation-changed hook for mongodb/0'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.current = 'idle'
09:20:17 INFO wait: status changed:
- .apps['mongodb'].units['mongodb/0'].juju_status.message = 'running database-relation-changed hook'
+ .apps['mongodb'].units['mongodb/0'].juju_status.message = 'running database-relation-joined hook for test-qh11xhus/0'
- .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.current = 'idle'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.current = 'executing'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.message = 'running mongodb-relation-changed hook'
09:20:18 INFO wait: status changed:
- .apps['mongodb'].units['mongodb/0'].juju_status.message = 'running database-relation-joined hook for test-qh11xhus/0'
+ .apps['mongodb'].units['mongodb/0'].juju_status.message = 'running database-relation-changed hook for test-qh11xhus/0'
09:20:22 INFO wait: status changed:
- .apps['mongodb'].units['mongodb/0'].juju_status.message = 'running database-relation-changed hook for test-qh11xhus/0'
+ .apps['mongodb'].units['mongodb/0'].juju_status.message = 'running database-peers-relation-changed hook'
09:20:24 INFO wait: status changed:
- .apps['mongodb'].units['mongodb/0'].juju_status.current = 'executing'
- .apps['mongodb'].units['mongodb/0'].juju_status.message = 'running database-peers-relation-changed hook'
+ .apps['mongodb'].units['mongodb/0'].juju_status.current = 'idle'
09:20:34 INFO wait: status changed:
- .apps['mongodb'].units['mongodb/0'].juju_status.current = 'idle'
+ .apps['mongodb'].units['mongodb/0'].juju_status.current = 'executing'
+ .apps['mongodb'].units['mongodb/0'].juju_status.message = 'running database-relation-changed hook for test-qh11xhus/0'
- .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.current = 'executing'
- .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.message = 'running mongodb-relation-changed hook'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.current = 'idle'
09:20:36 INFO wait: status changed:
- .apps['mongodb'].units['mongodb/0'].juju_status.current = 'executing'
- .apps['mongodb'].units['mongodb/0'].juju_status.message = 'running database-relation-changed hook for test-qh11xhus/0'
+ .apps['mongodb'].units['mongodb/0'].juju_status.current = 'idle'
- .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.current = 'idle'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.current = 'executing'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.message = 'running mongodb-relation-changed hook'
09:20:37 INFO wait: status changed:
- .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.current = 'executing'
- .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.message = 'running mongodb-relation-changed hook'
+ .apps['test-qh11xhus'].units['test-qh11xhus/0'].juju_status.current = 'idle'
09:20:40 INFO Waiting for model:
  test-qh11xhus/0 [idle] active: 
09:21:11 INFO Waiting for model:
  test-qh11xhus/0 [idle] active: 
09:21:13 INFO Current reconcile ID: efbc55f0-50a7-4849-9cbe-54580348f3ac
09:22:14 INFO Current reconcile ID: efbc55f0-50a7-4849-9cbe-54580348f3ac
09:23:15 INFO Current reconcile ID: efbc55f0-50a7-4849-9cbe-54580348f3ac
09:24:16 INFO Current reconcile ID: efbc55f0-50a7-4849-9cbe-54580348f3ac
09:25:18 INFO Current reconcile ID: efbc55f0-50a7-4849-9cbe-54580348f3ac
09:26:19 INFO Current reconcile ID: efbc55f0-50a7-4849-9cbe-54580348f3ac
09:27:20 INFO Current reconcile ID: efbc55f0-50a7-4849-9cbe-54580348f3ac
09:28:21 INFO Current reconcile ID: efbc55f0-50a7-4849-9cbe-54580348f3ac
09:29:22 INFO Current reconcile ID: efbc55f0-50a7-4849-9cbe-54580348f3ac
09:30:23 INFO Current reconcile ID: efbc55f0-50a7-4849-9cbe-54580348f3ac
09:31:24 INFO Current reconcile ID: efbc55f0-50a7-4849-9cbe-54580348f3ac
09:31:25 INFO Waiting for first check job status.
09:31:26 INFO 10.5.15.133 - - [12/Aug/2025 09:31:26] "GET /v1/jobs/99 HTTP/1.1" 200 -
09:31:26 INFO server log: [(<Request 'http://10.145.216.110:8000/v1/jobs/99' [GET]>, <Response 126 bytes [200 OK]>)] 
09:31:26 INFO Waiting for runner to be registered.
09:31:26 INFO 10.5.15.133 - - [12/Aug/2025 09:31:26] "POST /v1/runners/register HTTP/1.1" 200 -
09:31:26 INFO server log: [(<Request 'http://10.145.216.110:8000/v1/jobs/99' [GET]>, <Response 126 bytes [200 OK]>), (<Request 'http://10.145.216.110:8000/v1/runners/register' [POST]>, <Response 40 bytes [200 OK]>)] 
09:31:26 INFO handler health <RequestHandler uri='/v1/runners/1234/health' method='GET' query_string=None headers={'Authorization': 'Bearer c8e00b0b688542f2'} data=None json=<UNDEFINED>>
09:31:26 INFO trying to prepare tunnel for builder agent
09:31:29 INFO no runner or two or more runners in unit, return False
09:31:29 INFO Wait for condition not met, sleeping 10
09:31:39 INFO trying to prepare tunnel for builder agent
09:31:41 INFO no runner or two or more runners in unit, return False
09:31:41 INFO Wait for condition not met, sleeping 10
09:31:51 INFO trying to prepare tunnel for builder agent
09:31:54 INFO no runner or two or more runners in unit, return False
09:31:54 INFO Wait for condition not met, sleeping 10
09:32:04 INFO trying to prepare tunnel for builder agent
09:32:06 INFO no runner or two or more runners in unit, return False
09:32:06 INFO Wait for condition not met, sleeping 10
09:32:16 INFO trying to prepare tunnel for builder agent
09:32:17 INFO no runner or two or more runners in unit, return False
09:32:17 INFO Wait for condition not met, sleeping 10
09:32:27 INFO trying to prepare tunnel for builder agent
09:32:29 INFO no runner or two or more runners in unit, return False
09:32:29 INFO Wait for condition not met, sleeping 10
09:32:39 INFO trying to prepare tunnel for builder agent
09:32:41 INFO no runner or two or more runners in unit, return False
09:32:41 INFO Wait for condition not met, sleeping 10
09:32:51 INFO trying to prepare tunnel for builder agent
09:32:53 INFO no runner or two or more runners in unit, return False
09:32:53 INFO Wait for condition not met, sleeping 10
09:33:03 INFO trying to prepare tunnel for builder agent
09:33:09 INFO no runner or two or more runners in unit, return False
09:33:09 INFO Wait for condition not met, sleeping 10
09:33:19 INFO trying to prepare tunnel for builder agent
09:33:22 INFO no runner or two or more runners in unit, return False
09:33:22 INFO Wait for condition not met, sleeping 10
09:33:32 INFO trying to prepare tunnel for builder agent
09:33:35 INFO no runner or two or more runners in unit, return False
09:33:35 INFO Wait for condition not met, sleeping 10
09:33:45 INFO trying to prepare tunnel for builder agent
09:33:47 INFO no runner or two or more runners in unit, return False
09:33:47 INFO Wait for condition not met, sleeping 10
09:33:57 INFO trying to prepare tunnel for builder agent
09:33:59 INFO no runner or two or more runners in unit, return False
09:33:59 INFO Wait for condition not met, sleeping 10
09:34:09 INFO trying to prepare tunnel for builder agent
09:34:11 INFO no runner or two or more runners in unit, return False
09:34:11 INFO Wait for condition not met, sleeping 10
09:34:21 INFO trying to prepare tunnel for builder agent
09:34:23 INFO no runner or two or more runners in unit, return False
09:34:23 INFO Wait for condition not met, sleeping 10
09:34:33 INFO trying to prepare tunnel for builder agent
09:34:35 INFO no runner or two or more runners in unit, return False
09:34:35 INFO Wait for condition not met, sleeping 10
09:34:45 INFO trying to prepare tunnel for builder agent
09:34:47 INFO no runner or two or more runners in unit, return False
09:34:47 INFO Wait for condition not met, sleeping 10
09:34:57 INFO trying to prepare tunnel for builder agent
09:35:00 INFO no runner or two or more runners in unit, return False
09:35:00 INFO Wait for condition not met, sleeping 10
09:35:10 INFO trying to prepare tunnel for builder agent
09:35:11 INFO no runner or two or more runners in unit, return False
09:35:11 INFO Wait for condition not met, sleeping 10
09:35:21 INFO trying to prepare tunnel for builder agent
09:35:23 INFO no runner or two or more runners in unit, return False
09:35:23 INFO Wait for condition not met, sleeping 10
09:35:33 INFO trying to prepare tunnel for builder agent
09:35:36 INFO no runner or two or more runners in unit, return False
09:35:36 INFO Wait for condition not met, sleeping 10
09:35:46 INFO trying to prepare tunnel for builder agent
09:35:48 INFO no runner or two or more runners in unit, return False
09:35:48 INFO Wait for condition not met, sleeping 10
09:35:58 INFO trying to prepare tunnel for builder agent
09:36:01 INFO no runner or two or more runners in unit, return False
09:36:01 INFO Wait for condition not met, sleeping 10
09:36:11 INFO trying to prepare tunnel for builder agent
09:36:12 INFO no runner or two or more runners in unit, return False
09:36:12 INFO Wait for condition not met, sleeping 10
09:36:22 INFO trying to prepare tunnel for builder agent
09:36:24 INFO no runner or two or more runners in unit, return False
09:36:24 INFO Wait for condition not met, sleeping 10
09:36:34 INFO trying to prepare tunnel for builder agent
09:36:36 INFO no runner or two or more runners in unit, return False
09:36:36 INFO Wait for condition not met, sleeping 10
09:36:46 INFO trying to prepare tunnel for builder agent
09:36:50 INFO no runner or two or more runners in unit, return False
09:36:50 INFO Wait for condition not met, sleeping 10
09:37:00 INFO trying to prepare tunnel for builder agent
09:37:02 INFO no runner or two or more runners in unit, return False
09:37:02 INFO Wait for condition not met, sleeping 10
09:37:12 INFO trying to prepare tunnel for builder agent
09:37:13 INFO 10.5.15.133 - - [12/Aug/2025 09:37:13] "GET /v1/jobs/99 HTTP/1.1" 200 -
09:37:13 INFO 10.5.15.133 - - [12/Aug/2025 09:37:13] "[35m[1mPOST /v1/runners/register HTTP/1.1[0m" 500 -
09:37:15 INFO no runner or two or more runners in unit, return False
09:37:15 INFO Wait for condition not met, sleeping 10
09:37:25 INFO trying to prepare tunnel for builder agent
09:37:27 INFO no runner or two or more runners in unit, return False
09:37:27 INFO Wait for condition not met, sleeping 10
09:37:37 INFO trying to prepare tunnel for builder agent
09:37:39 INFO no runner or two or more runners in unit, return False
09:37:39 INFO Wait for condition not met, sleeping 10
09:37:49 INFO trying to prepare tunnel for builder agent
09:37:51 INFO no runner or two or more runners in unit, return False
09:37:51 INFO Wait for condition not met, sleeping 10
09:38:01 INFO trying to prepare tunnel for builder agent
09:38:03 INFO no runner or two or more runners in unit, return False
09:38:03 INFO Wait for condition not met, sleeping 10
09:38:13 INFO trying to prepare tunnel for builder agent
09:38:17 INFO no runner or two or more runners in unit, return False
09:38:17 INFO Wait for condition not met, sleeping 10
09:38:27 INFO trying to prepare tunnel for builder agent
09:38:29 INFO no runner or two or more runners in unit, return False
09:38:29 INFO Wait for condition not met, sleeping 10
09:38:39 INFO trying to prepare tunnel for builder agent
09:38:40 INFO no runner or two or more runners in unit, return False
09:38:40 INFO Wait for condition not met, sleeping 10
09:38:50 INFO trying to prepare tunnel for builder agent
09:38:53 INFO no runner or two or more runners in unit, return False
09:38:53 INFO Wait for condition not met, sleeping 10
09:39:03 INFO trying to prepare tunnel for builder agent
09:39:05 INFO no runner or two or more runners in unit, return False
09:39:05 INFO Wait for condition not met, sleeping 10
09:39:15 INFO trying to prepare tunnel for builder agent
09:39:17 INFO no runner or two or more runners in unit, return False
09:39:17 INFO Wait for condition not met, sleeping 10
09:39:27 INFO trying to prepare tunnel for builder agent
09:39:30 INFO no runner or two or more runners in unit, return False
09:39:30 INFO Wait for condition not met, sleeping 10
09:39:40 INFO trying to prepare tunnel for builder agent
09:39:42 INFO no runner or two or more runners in unit, return False
09:39:42 INFO Wait for condition not met, sleeping 10
09:39:52 INFO trying to prepare tunnel for builder agent
09:39:54 INFO no runner or two or more runners in unit, return False
09:39:54 INFO Wait for condition not met, sleeping 10
09:40:04 INFO trying to prepare tunnel for builder agent
09:40:08 INFO no runner or two or more runners in unit, return False
09:40:08 INFO Wait for condition not met, sleeping 10
09:40:18 INFO trying to prepare tunnel for builder agent
09:40:21 INFO no runner or two or more runners in unit, return False
09:40:21 INFO Wait for condition not met, sleeping 10
09:40:31 INFO trying to prepare tunnel for builder agent
09:40:32 INFO no runner or two or more runners in unit, return False
09:40:32 INFO Wait for condition not met, sleeping 10
09:40:42 INFO trying to prepare tunnel for builder agent
09:40:48 INFO no runner or two or more runners in unit, return False
09:40:48 INFO Wait for condition not met, sleeping 10
09:40:58 INFO trying to prepare tunnel for builder agent
09:41:00 INFO no runner or two or more runners in unit, return False
09:41:00 INFO Wait for condition not met, sleeping 10
09:41:10 INFO trying to prepare tunnel for builder agent
09:41:12 INFO no runner or two or more runners in unit, return False
09:41:12 INFO Wait for condition not met, sleeping 10
09:41:22 INFO trying to prepare tunnel for builder agent
09:41:26 INFO no runner or two or more runners in unit, return False
09:41:26 INFO Wait for condition not met, sleeping 10
09:41:36 INFO trying to prepare tunnel for builder agent
09:41:38 INFO no runner or two or more runners in unit, return False
09:41:38 INFO Waiting for model:
  test-qh11xhus/0 [idle] active: 
09:42:08 INFO Waiting for model:
  test-qh11xhus/0 [idle] active: 
09:42:11 INFO Current reconcile ID: 2dc9e098-e8cf-4882-a882-556c0022ce5e
09:43:12 INFO Current reconcile ID: 2dc9e098-e8cf-4882-a882-556c0022ce5e
09:44:13 INFO Current reconcile ID: 15aee8d6-1487-48b3-9693-92c14372858e
09:44:13 INFO Waiting for model:
  test-qh11xhus/0 [idle] active: 
09:44:30 INFO Current reconcile ID: 15aee8d6-1487-48b3-9693-92c14372858e
09:45:31 INFO Current reconcile ID: 15aee8d6-1487-48b3-9693-92c14372858e
09:46:32 INFO Current reconcile ID: 69d4882e-ee2e-4e57-a54c-5c9db2bea302
09:46:33 INFO Application log: 
2025-08-12 09:16:23,867 - INFO - root - Starting GitHub runner manager service version: 0.6.1
2025-08-12 09:16:23,877 - INFO - github_runner_manager.http_server - Starting the server...
2025-08-12 09:16:23,878 - INFO - github_runner_manager.reconcile_service - Starting the reconcile service...
 * Serving Flask app 'github_runner_manager.http_server'
2025-08-12 09:16:23,878 - INFO - github_runner_manager.reconcile_service - Start reconciliation
 * Debug mode: off
2025-08-12 09:16:23,912 - INFO - werkzeug - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:55555
2025-08-12 09:16:23,913 - INFO - werkzeug - [33mPress CTRL+C to quit[0m
2025-08-12 09:16:23,913 - INFO - github_runner_manager.manager.runner_scaler - Start reconcile. base_quantity 0. max_quantity: 0.
2025-08-12 09:16:23,913 - INFO - github_runner_manager.manager.runner_manager - runner_manager::cleanup
2025-08-12 09:16:23,913 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: False, force: False
2025-08-12 09:16:23,913 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:16:26,781 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:16:27,958 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:16:30,208 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:16:30,209 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:16:30,209 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:16:30,236 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:16:34,078 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:16:34,079 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:16:34,079 - INFO - github_runner_manager.manager.runner_scaler - Reconcile runners from 0 to 0
2025-08-12 09:16:34,079 - INFO - github_runner_manager.manager.runner_scaler - No changes to the number of runners.
2025-08-12 09:16:34,079 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:16:37,811 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:16:37,812 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:16:37,812 - INFO - github_runner_manager.manager.runner_scaler - Found 0 busy runners: []
2025-08-12 09:16:37,812 - INFO - github_runner_manager.manager.runner_scaler - Found 0 idle runners: []
2025-08-12 09:16:37,812 - INFO - github_runner_manager.manager.runner_scaler - Found 0 offline runners that are healthy: []
2025-08-12 09:16:37,812 - INFO - github_runner_manager.manager.runner_scaler - Found 0 unhealthy runners: []
2025-08-12 09:16:37,812 - INFO - github_runner_manager.manager.runner_scaler - Current available runners (idle + healthy offline): set()
2025-08-12 09:16:37,812 - INFO - github_runner_manager.manager.runner_scaler - Current active runners: set()
2025-08-12 09:16:37,813 - INFO - github_runner_manager.manager.runner_scaler - Finished reconciliation.
2025-08-12 09:16:37,813 - INFO - github_runner_manager.reconcile_service - Change in number of runner after reconcile: 0
2025-08-12 09:16:37,813 - INFO - github_runner_manager.reconcile_service - End reconciliation
2025-08-12 09:16:38,088 - INFO - werkzeug - 127.0.0.1 - - [12/Aug/2025 09:16:38] "[35m[1mGET /health HTTP/1.1[0m" 204 -
2025-08-12 09:16:38,102 - INFO - werkzeug - 127.0.0.1 - - [12/Aug/2025 09:16:38] "[35m[1mGET /health HTTP/1.1[0m" 204 -
2025-08-12 09:16:38,116 - INFO - github_runner_manager.http_server - Attempting to acquire the lock: unlocked
2025-08-12 09:16:38,116 - INFO - github_runner_manager.http_server - Flushing runners...
2025-08-12 09:16:38,153 - INFO - github_runner_manager.http_server - Flushing busy: False
2025-08-12 09:16:38,153 - INFO - github_runner_manager.manager.runner_manager - runner_manager::cleanup
2025-08-12 09:16:38,153 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: False, force: False
2025-08-12 09:16:38,153 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:16:41,283 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:16:42,453 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:16:44,879 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:16:44,879 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:16:44,879 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:16:44,905 - INFO - github_runner_manager.manager.runner_manager - runner_manager::flush_runners. mode FlushMode.FLUSH_IDLE
2025-08-12 09:16:44,905 - INFO - github_runner_manager.manager.runner_manager - Flushing idle runners...
2025-08-12 09:16:44,905 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: True, force: False
2025-08-12 09:16:44,905 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:16:47,428 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:16:48,666 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:16:51,440 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:16:51,441 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:16:51,441 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:16:51,466 - INFO - github_runner_manager.http_server - Flushed 0 runners
2025-08-12 09:16:51,467 - INFO - werkzeug - 127.0.0.1 - - [12/Aug/2025 09:16:51] "[35m[1mPOST /runner/flush?flush-busy=False HTTP/1.1[0m" 204 -
2025-08-12 09:17:24,804 - INFO - root - Starting GitHub runner manager service version: 0.6.1
2025-08-12 09:17:24,814 - INFO - github_runner_manager.http_server - Starting the server...
2025-08-12 09:17:24,814 - INFO - github_runner_manager.reconcile_service - Starting the reconcile service...
 * Serving Flask app 'github_runner_manager.http_server'
2025-08-12 09:17:24,815 - INFO - github_runner_manager.reconcile_service - Start reconciliation
 * Debug mode: off
2025-08-12 09:17:24,816 - INFO - github_runner_manager.manager.runner_scaler - Start reconcile. base_quantity 0. max_quantity: 0.
2025-08-12 09:17:24,816 - INFO - github_runner_manager.manager.runner_manager - runner_manager::cleanup
2025-08-12 09:17:24,816 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: False, force: False
2025-08-12 09:17:24,816 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:17:24,817 - INFO - werkzeug - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:55555
2025-08-12 09:17:24,817 - INFO - werkzeug - [33mPress CTRL+C to quit[0m
2025-08-12 09:17:27,446 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:17:27,446 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:17:30,305 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:17:30,305 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:17:30,305 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:17:30,334 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:17:33,094 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:17:33,094 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:17:33,094 - INFO - github_runner_manager.manager.runner_scaler - Reconcile runners from 0 to 0
2025-08-12 09:17:33,094 - INFO - github_runner_manager.manager.runner_scaler - No changes to the number of runners.
2025-08-12 09:17:33,094 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:17:36,956 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:17:36,956 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:17:36,956 - INFO - github_runner_manager.manager.runner_scaler - Found 0 busy runners: []
2025-08-12 09:17:36,956 - INFO - github_runner_manager.manager.runner_scaler - Found 0 idle runners: []
2025-08-12 09:17:36,956 - INFO - github_runner_manager.manager.runner_scaler - Found 0 offline runners that are healthy: []
2025-08-12 09:17:36,956 - INFO - github_runner_manager.manager.runner_scaler - Found 0 unhealthy runners: []
2025-08-12 09:17:36,957 - INFO - github_runner_manager.manager.runner_scaler - Current available runners (idle + healthy offline): set()
2025-08-12 09:17:36,957 - INFO - github_runner_manager.manager.runner_scaler - Current active runners: set()
2025-08-12 09:17:36,957 - INFO - github_runner_manager.manager.runner_scaler - Finished reconciliation.
2025-08-12 09:17:36,957 - INFO - github_runner_manager.reconcile_service - Change in number of runner after reconcile: 0
2025-08-12 09:17:36,957 - INFO - github_runner_manager.reconcile_service - End reconciliation
2025-08-12 09:17:39,069 - INFO - werkzeug - 127.0.0.1 - - [12/Aug/2025 09:17:39] "[35m[1mGET /health HTTP/1.1[0m" 204 -
2025-08-12 09:17:39,089 - INFO - werkzeug - 127.0.0.1 - - [12/Aug/2025 09:17:39] "[35m[1mGET /health HTTP/1.1[0m" 204 -
2025-08-12 09:17:39,099 - INFO - github_runner_manager.http_server - Attempting to acquire the lock: unlocked
2025-08-12 09:17:39,099 - INFO - github_runner_manager.http_server - Flushing runners...
2025-08-12 09:17:39,099 - INFO - github_runner_manager.http_server - Flushing busy: False
2025-08-12 09:17:39,100 - INFO - github_runner_manager.manager.runner_manager - runner_manager::cleanup
2025-08-12 09:17:39,100 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: False, force: False
2025-08-12 09:17:39,100 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:17:41,988 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:17:41,988 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:17:45,014 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:17:45,014 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:17:45,014 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:17:45,044 - INFO - github_runner_manager.manager.runner_manager - runner_manager::flush_runners. mode FlushMode.FLUSH_IDLE
2025-08-12 09:17:45,044 - INFO - github_runner_manager.manager.runner_manager - Flushing idle runners...
2025-08-12 09:17:45,044 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: True, force: False
2025-08-12 09:17:45,044 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:17:47,540 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:17:47,540 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:17:51,999 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:17:51,999 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:17:51,999 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:17:52,027 - INFO - github_runner_manager.http_server - Flushed 0 runners
2025-08-12 09:17:52,027 - INFO - werkzeug - 127.0.0.1 - - [12/Aug/2025 09:17:52] "[35m[1mPOST /runner/flush?flush-busy=False HTTP/1.1[0m" 204 -
2025-08-12 09:19:36,990 - INFO - github_runner_manager.reconcile_service - Start reconciliation
2025-08-12 09:19:36,991 - INFO - github_runner_manager.manager.runner_scaler - Start reconcile. base_quantity 0. max_quantity: 0.
2025-08-12 09:19:36,991 - INFO - github_runner_manager.manager.runner_manager - runner_manager::cleanup
2025-08-12 09:19:36,991 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: False, force: False
2025-08-12 09:19:36,991 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:19:39,737 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:19:39,737 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:19:42,253 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:19:42,254 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:19:42,254 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:19:42,281 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:19:44,565 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:19:44,565 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:19:44,565 - INFO - github_runner_manager.manager.runner_scaler - Reconcile runners from 0 to 0
2025-08-12 09:19:44,565 - INFO - github_runner_manager.manager.runner_scaler - No changes to the number of runners.
2025-08-12 09:19:44,565 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:19:47,019 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:19:47,020 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:19:47,020 - INFO - github_runner_manager.manager.runner_scaler - Found 0 busy runners: []
2025-08-12 09:19:47,020 - INFO - github_runner_manager.manager.runner_scaler - Found 0 idle runners: []
2025-08-12 09:19:47,020 - INFO - github_runner_manager.manager.runner_scaler - Found 0 offline runners that are healthy: []
2025-08-12 09:19:47,020 - INFO - github_runner_manager.manager.runner_scaler - Found 0 unhealthy runners: []
2025-08-12 09:19:47,020 - INFO - github_runner_manager.manager.runner_scaler - Current available runners (idle + healthy offline): set()
2025-08-12 09:19:47,020 - INFO - github_runner_manager.manager.runner_scaler - Current active runners: set()
2025-08-12 09:19:47,021 - INFO - github_runner_manager.manager.runner_scaler - Finished reconciliation.
2025-08-12 09:19:47,021 - INFO - github_runner_manager.reconcile_service - Change in number of runner after reconcile: 0
2025-08-12 09:19:47,021 - INFO - github_runner_manager.reconcile_service - End reconciliation
2025-08-12 09:20:18,795 - INFO - root - Starting GitHub runner manager service version: 0.6.1
2025-08-12 09:20:18,807 - INFO - github_runner_manager.http_server - Starting the server...
 * Serving Flask app 'github_runner_manager.http_server'
 * Debug mode: off
2025-08-12 09:20:18,808 - INFO - github_runner_manager.reconcile_service - Starting the reconcile service...
2025-08-12 09:20:18,809 - INFO - github_runner_manager.reconcile_service - Start reconciliation
2025-08-12 09:20:18,810 - INFO - github_runner_manager.manager.runner_scaler - Start reconcile. base_quantity 0. max_quantity: 0.
2025-08-12 09:20:18,810 - INFO - github_runner_manager.manager.runner_scaler - Reactive configuration detected, spawning runners in reactive mode.
2025-08-12 09:20:18,810 - INFO - github_runner_manager.manager.runner_manager - runner_manager::cleanup
2025-08-12 09:20:18,810 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: False, force: False
2025-08-12 09:20:18,810 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:20:18,811 - INFO - werkzeug - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:55555
2025-08-12 09:20:18,811 - INFO - werkzeug - [33mPress CTRL+C to quit[0m
2025-08-12 09:20:21,898 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:20:21,898 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:20:25,103 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:20:25,103 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:20:25,103 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:20:25,309 - INFO - github_runner_manager.reactive.runner_manager - Reactive reconcile. Flushing on empty queue
2025-08-12 09:20:25,310 - INFO - github_runner_manager.manager.runner_manager - runner_manager::flush_runners. mode FlushMode.FLUSH_IDLE
2025-08-12 09:20:25,310 - INFO - github_runner_manager.manager.runner_manager - Flushing idle runners...
2025-08-12 09:20:25,310 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: True, force: False
2025-08-12 09:20:25,310 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:20:27,771 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:20:27,772 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:20:30,157 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:20:30,157 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:20:30,157 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:20:30,189 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:20:32,793 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:20:32,793 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:20:32,793 - INFO - github_runner_manager.utilities - Executing command ['ps', 'axo', 'cmd:57,pid', '--no-headers', '--sort=-start_time']
2025-08-12 09:20:32,800 - INFO - github_runner_manager.reactive.process_manager - Reactive runner processes: current quantity 0, expected quantity 0
2025-08-12 09:20:32,800 - INFO - github_runner_manager.reactive.process_manager - No changes to number of reactive runner processes needed.
2025-08-12 09:20:32,800 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:20:33,009 - INFO - werkzeug - 127.0.0.1 - - [12/Aug/2025 09:20:33] "[35m[1mGET /health HTTP/1.1[0m" 204 -
2025-08-12 09:20:35,293 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:20:35,293 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:20:35,293 - INFO - github_runner_manager.manager.runner_scaler - Found 0 busy runners: []
2025-08-12 09:20:35,293 - INFO - github_runner_manager.manager.runner_scaler - Found 0 idle runners: []
2025-08-12 09:20:35,293 - INFO - github_runner_manager.manager.runner_scaler - Found 0 offline runners that are healthy: []
2025-08-12 09:20:35,293 - INFO - github_runner_manager.manager.runner_scaler - Found 0 unhealthy runners: []
2025-08-12 09:20:35,294 - INFO - github_runner_manager.manager.runner_scaler - Current available runners (idle + healthy offline): set()
2025-08-12 09:20:35,294 - INFO - github_runner_manager.manager.runner_scaler - Current active runners: set()
2025-08-12 09:20:35,294 - INFO - github_runner_manager.manager.runner_scaler - Finished reconciliation.
2025-08-12 09:20:35,294 - INFO - github_runner_manager.reconcile_service - Change in number of runner after reconcile: 0
2025-08-12 09:20:35,294 - INFO - github_runner_manager.reconcile_service - End reconciliation
2025-08-12 09:20:43,029 - INFO - root - Starting GitHub runner manager service version: 0.6.1
2025-08-12 09:20:43,040 - INFO - github_runner_manager.http_server - Starting the server...
 * Serving Flask app 'github_runner_manager.http_server'
2025-08-12 09:20:43,041 - INFO - github_runner_manager.reconcile_service - Starting the reconcile service...
 * Debug mode: off
2025-08-12 09:20:43,043 - INFO - werkzeug - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:55555
2025-08-12 09:20:43,043 - INFO - werkzeug - [33mPress CTRL+C to quit[0m
2025-08-12 09:20:43,043 - INFO - github_runner_manager.reconcile_service - Start reconciliation
2025-08-12 09:20:43,044 - INFO - github_runner_manager.manager.runner_scaler - Start reconcile. base_quantity 0. max_quantity: 1.
2025-08-12 09:20:43,044 - INFO - github_runner_manager.manager.runner_scaler - Reactive configuration detected, spawning runners in reactive mode.
2025-08-12 09:20:43,044 - INFO - github_runner_manager.manager.runner_manager - runner_manager::cleanup
2025-08-12 09:20:43,044 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: False, force: False
2025-08-12 09:20:43,044 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:20:47,561 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:20:47,561 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:20:50,989 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:20:50,989 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:20:50,989 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:20:51,145 - INFO - github_runner_manager.reactive.runner_manager - Reactive reconcile. Flushing on empty queue
2025-08-12 09:20:51,145 - INFO - github_runner_manager.manager.runner_manager - runner_manager::flush_runners. mode FlushMode.FLUSH_IDLE
2025-08-12 09:20:51,145 - INFO - github_runner_manager.manager.runner_manager - Flushing idle runners...
2025-08-12 09:20:51,145 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: True, force: False
2025-08-12 09:20:51,145 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:20:54,285 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:20:54,286 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:20:56,816 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:20:56,816 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:20:56,816 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:20:56,856 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:20:57,269 - INFO - werkzeug - 127.0.0.1 - - [12/Aug/2025 09:20:57] "[35m[1mGET /health HTTP/1.1[0m" 204 -
2025-08-12 09:20:59,189 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:20:59,189 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:20:59,189 - INFO - github_runner_manager.utilities - Executing command ['ps', 'axo', 'cmd:57,pid', '--no-headers', '--sort=-start_time']
2025-08-12 09:20:59,195 - INFO - github_runner_manager.reactive.process_manager - Reactive runner processes: current quantity 0, expected quantity 1
2025-08-12 09:20:59,195 - INFO - github_runner_manager.reactive.process_manager - Will spawn 1 new reactive runner process(es)
2025-08-12 09:20:59,203 - INFO - github_runner_manager.reactive.process_manager - Spawned a new reactive runner process with pid 6026
2025-08-12 09:20:59,203 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:21:02,612 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:21:02,612 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:21:02,613 - INFO - github_runner_manager.manager.runner_scaler - Found 0 busy runners: []
2025-08-12 09:21:02,613 - INFO - github_runner_manager.manager.runner_scaler - Found 0 idle runners: []
2025-08-12 09:21:02,613 - INFO - github_runner_manager.manager.runner_scaler - Found 0 offline runners that are healthy: []
2025-08-12 09:21:02,613 - INFO - github_runner_manager.manager.runner_scaler - Found 0 unhealthy runners: []
2025-08-12 09:21:02,613 - INFO - github_runner_manager.manager.runner_scaler - Current available runners (idle + healthy offline): set()
2025-08-12 09:21:02,613 - INFO - github_runner_manager.manager.runner_scaler - Current active runners: set()
2025-08-12 09:21:02,614 - INFO - github_runner_manager.manager.runner_scaler - Finished reconciliation.
2025-08-12 09:21:02,614 - INFO - github_runner_manager.reconcile_service - Change in number of runner after reconcile: 1
2025-08-12 09:21:02,614 - INFO - github_runner_manager.reconcile_service - End reconciliation
2025-08-12 09:36:02,692 - INFO - github_runner_manager.reconcile_service - Start reconciliation
2025-08-12 09:36:02,694 - INFO - github_runner_manager.manager.runner_scaler - Start reconcile. base_quantity 0. max_quantity: 1.
2025-08-12 09:36:02,694 - INFO - github_runner_manager.manager.runner_scaler - Reactive configuration detected, spawning runners in reactive mode.
2025-08-12 09:36:02,694 - INFO - github_runner_manager.manager.runner_manager - runner_manager::cleanup
2025-08-12 09:36:02,694 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: False, force: False
2025-08-12 09:36:02,694 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:36:05,449 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:36:05,449 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:36:08,342 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:36:08,342 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:36:08,343 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:36:08,411 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:36:11,005 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:36:11,005 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:36:11,005 - INFO - github_runner_manager.utilities - Executing command ['ps', 'axo', 'cmd:57,pid', '--no-headers', '--sort=-start_time']
2025-08-12 09:36:11,016 - INFO - github_runner_manager.reactive.process_manager - Reactive runner processes: current quantity 0, expected quantity 1
2025-08-12 09:36:11,016 - INFO - github_runner_manager.reactive.process_manager - Will spawn 1 new reactive runner process(es)
2025-08-12 09:36:11,027 - INFO - github_runner_manager.reactive.process_manager - Spawned a new reactive runner process with pid 6298
2025-08-12 09:36:11,027 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:36:14,729 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:36:14,729 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:36:14,729 - INFO - github_runner_manager.manager.runner_scaler - Found 0 busy runners: []
2025-08-12 09:36:14,729 - INFO - github_runner_manager.manager.runner_scaler - Found 0 idle runners: []
2025-08-12 09:36:14,729 - INFO - github_runner_manager.manager.runner_scaler - Found 0 offline runners that are healthy: []
2025-08-12 09:36:14,729 - INFO - github_runner_manager.manager.runner_scaler - Found 0 unhealthy runners: []
2025-08-12 09:36:14,729 - INFO - github_runner_manager.manager.runner_scaler - Current available runners (idle + healthy offline): set()
2025-08-12 09:36:14,729 - INFO - github_runner_manager.manager.runner_scaler - Current active runners: set()
2025-08-12 09:36:14,730 - INFO - github_runner_manager.manager.runner_scaler - Finished reconciliation.
2025-08-12 09:36:14,730 - INFO - github_runner_manager.reconcile_service - Change in number of runner after reconcile: 1
2025-08-12 09:36:14,730 - INFO - github_runner_manager.reconcile_service - End reconciliation
2025-08-12 09:41:40,486 - INFO - root - Starting GitHub runner manager service version: 0.6.1
2025-08-12 09:41:40,497 - INFO - github_runner_manager.http_server - Starting the server...
2025-08-12 09:41:40,498 - INFO - github_runner_manager.reconcile_service - Starting the reconcile service...
 * Serving Flask app 'github_runner_manager.http_server'
2025-08-12 09:41:40,498 - INFO - github_runner_manager.reconcile_service - Start reconciliation
 * Debug mode: off
2025-08-12 09:41:40,499 - INFO - github_runner_manager.manager.runner_scaler - Start reconcile. base_quantity 0. max_quantity: 0.
2025-08-12 09:41:40,499 - INFO - github_runner_manager.manager.runner_scaler - Reactive configuration detected, spawning runners in reactive mode.
2025-08-12 09:41:40,499 - INFO - github_runner_manager.manager.runner_manager - runner_manager::cleanup
2025-08-12 09:41:40,499 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: False, force: False
2025-08-12 09:41:40,499 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:41:40,501 - INFO - werkzeug - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:55555
2025-08-12 09:41:40,501 - INFO - werkzeug - [33mPress CTRL+C to quit[0m
2025-08-12 09:41:42,932 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:41:42,932 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:41:45,507 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:41:45,507 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:41:45,507 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:41:45,655 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:41:48,497 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:41:48,497 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:41:48,497 - INFO - github_runner_manager.utilities - Executing command ['ps', 'axo', 'cmd:57,pid', '--no-headers', '--sort=-start_time']
2025-08-12 09:41:48,503 - INFO - github_runner_manager.reactive.process_manager - Reactive runner processes: current quantity 0, expected quantity 0
2025-08-12 09:41:48,503 - INFO - github_runner_manager.reactive.process_manager - No changes to number of reactive runner processes needed.
2025-08-12 09:41:48,503 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:41:51,838 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:41:51,838 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:41:51,838 - INFO - github_runner_manager.manager.runner_scaler - Found 0 busy runners: []
2025-08-12 09:41:51,838 - INFO - github_runner_manager.manager.runner_scaler - Found 0 idle runners: []
2025-08-12 09:41:51,838 - INFO - github_runner_manager.manager.runner_scaler - Found 0 offline runners that are healthy: []
2025-08-12 09:41:51,838 - INFO - github_runner_manager.manager.runner_scaler - Found 0 unhealthy runners: []
2025-08-12 09:41:51,838 - INFO - github_runner_manager.manager.runner_scaler - Current available runners (idle + healthy offline): set()
2025-08-12 09:41:51,839 - INFO - github_runner_manager.manager.runner_scaler - Current active runners: set()
2025-08-12 09:41:51,839 - INFO - github_runner_manager.manager.runner_scaler - Finished reconciliation.
2025-08-12 09:41:51,839 - INFO - github_runner_manager.reconcile_service - Change in number of runner after reconcile: 0
2025-08-12 09:41:51,839 - INFO - github_runner_manager.reconcile_service - End reconciliation
2025-08-12 09:41:54,698 - INFO - werkzeug - 127.0.0.1 - - [12/Aug/2025 09:41:54] "[35m[1mGET /health HTTP/1.1[0m" 204 -
2025-08-12 09:43:51,938 - INFO - github_runner_manager.reconcile_service - Start reconciliation
2025-08-12 09:43:51,939 - INFO - github_runner_manager.manager.runner_scaler - Start reconcile. base_quantity 0. max_quantity: 0.
2025-08-12 09:43:51,940 - INFO - github_runner_manager.manager.runner_scaler - Reactive configuration detected, spawning runners in reactive mode.
2025-08-12 09:43:51,940 - INFO - github_runner_manager.manager.runner_manager - runner_manager::cleanup
2025-08-12 09:43:51,940 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: False, force: False
2025-08-12 09:43:51,940 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:43:56,663 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:43:56,664 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:43:59,802 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:43:59,802 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:43:59,802 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:43:59,847 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:44:02,670 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:44:02,670 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:44:02,670 - INFO - github_runner_manager.utilities - Executing command ['ps', 'axo', 'cmd:57,pid', '--no-headers', '--sort=-start_time']
2025-08-12 09:44:02,677 - INFO - github_runner_manager.reactive.process_manager - Reactive runner processes: current quantity 0, expected quantity 0
2025-08-12 09:44:02,677 - INFO - github_runner_manager.reactive.process_manager - No changes to number of reactive runner processes needed.
2025-08-12 09:44:02,677 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:44:08,730 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:44:08,731 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:44:08,731 - INFO - github_runner_manager.manager.runner_scaler - Found 0 busy runners: []
2025-08-12 09:44:08,731 - INFO - github_runner_manager.manager.runner_scaler - Found 0 idle runners: []
2025-08-12 09:44:08,731 - INFO - github_runner_manager.manager.runner_scaler - Found 0 offline runners that are healthy: []
2025-08-12 09:44:08,731 - INFO - github_runner_manager.manager.runner_scaler - Found 0 unhealthy runners: []
2025-08-12 09:44:08,731 - INFO - github_runner_manager.manager.runner_scaler - Current available runners (idle + healthy offline): set()
2025-08-12 09:44:08,731 - INFO - github_runner_manager.manager.runner_scaler - Current active runners: set()
2025-08-12 09:44:08,731 - INFO - github_runner_manager.manager.runner_scaler - Finished reconciliation.
2025-08-12 09:44:08,731 - INFO - github_runner_manager.reconcile_service - Change in number of runner after reconcile: 0
2025-08-12 09:44:08,731 - INFO - github_runner_manager.reconcile_service - End reconciliation
2025-08-12 09:46:08,800 - INFO - github_runner_manager.reconcile_service - Start reconciliation
2025-08-12 09:46:08,801 - INFO - github_runner_manager.manager.runner_scaler - Start reconcile. base_quantity 0. max_quantity: 0.
2025-08-12 09:46:08,801 - INFO - github_runner_manager.manager.runner_scaler - Reactive configuration detected, spawning runners in reactive mode.
2025-08-12 09:46:08,801 - INFO - github_runner_manager.manager.runner_manager - runner_manager::cleanup
2025-08-12 09:46:08,801 - INFO - github_runner_manager.manager.runner_manager -  _cleanup_resources idle: False, force: False
2025-08-12 09:46:08,801 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:46:11,555 - INFO - github_runner_manager.manager.runner_manager - cleanup cloud_runners []
2025-08-12 09:46:11,556 - INFO - github_runner_manager.manager.runner_manager - cleanup health_response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:46:13,399 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up SSH key files
2025-08-12 09:46:13,399 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Found 0 key files, clean up 0 key files
2025-08-12 09:46:13,399 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Cleaning up openstack keypairs
2025-08-12 09:46:13,445 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:46:16,567 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:46:16,567 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:46:16,567 - INFO - github_runner_manager.utilities - Executing command ['ps', 'axo', 'cmd:57,pid', '--no-headers', '--sort=-start_time']
2025-08-12 09:46:16,573 - INFO - github_runner_manager.reactive.process_manager - Reactive runner processes: current quantity 0, expected quantity 0
2025-08-12 09:46:16,573 - INFO - github_runner_manager.reactive.process_manager - No changes to number of reactive runner processes needed.
2025-08-12 09:46:16,573 - INFO - github_runner_manager.openstack_cloud.openstack_cloud - Getting all openstack servers managed by the charm
2025-08-12 09:46:18,705 - INFO - github_runner_manager.manager.runner_manager - clouds runners response []
2025-08-12 09:46:18,705 - INFO - github_runner_manager.manager.runner_manager - runner health response RunnersHealthResponse(requested_runners=[], failed_requested_runners=[], non_requested_runners=[])
2025-08-12 09:46:18,705 - INFO - github_runner_manager.manager.runner_scaler - Found 0 busy runners: []
2025-08-12 09:46:18,705 - INFO - github_runner_manager.manager.runner_scaler - Found 0 idle runners: []
2025-08-12 09:46:18,705 - INFO - github_runner_manager.manager.runner_scaler - Found 0 offline runners that are healthy: []
2025-08-12 09:46:18,705 - INFO - github_runner_manager.manager.runner_scaler - Found 0 unhealthy runners: []
2025-08-12 09:46:18,705 - INFO - github_runner_manager.manager.runner_scaler - Current available runners (idle + healthy offline): set()
2025-08-12 09:46:18,705 - INFO - github_runner_manager.manager.runner_scaler - Current active runners: set()
2025-08-12 09:46:18,705 - INFO - github_runner_manager.manager.runner_scaler - Finished reconciliation.
2025-08-12 09:46:18,705 - INFO - github_runner_manager.reconcile_service - Change in number of runner after reconcile: 0
2025-08-12 09:46:18,706 - INFO - github_runner_manager.reconcile_service - End reconciliation

09:46:33 INFO OpenStack servers: []
09:46:33 INFO cli: juju debug-log --model github-pr-196a7-lxd:test-jobmanager-reactive-jaog --limit 1000
09:46:33 INFO Model status:

Model                          Controller           Cloud/Region         Version  SLA          Timestamp
test-jobmanager-reactive-jaog  github-pr-196a7-lxd  localhost/localhost  3.6.8    unsupported  09:46:33Z

App                                   Version  Status  Scale  Charm                        Channel      Rev  Exposed  Message
github-runner-image-builder-qh11xhus           active      1  github-runner-image-builder  latest/edge  100  no       
mongodb                               6.0.24   active      1  mongodb                      6/edge       224  no       
test-qh11xhus                                  active      1  github-runner                               0  no       

Unit                                     Workload  Agent  Machine  Public address  Ports      Message
github-runner-image-builder-qh11xhus/0*  active    idle   1        10.5.15.239                
mongodb/0*                               active    idle   0        10.5.15.77      27017/tcp  Primary.
test-qh11xhus/0*                         active    idle   2        10.5.15.133                

Machine  State    Address      Inst id        Base          AZ  Message
0        started  10.5.15.77   juju-3e1944-0  ubuntu@22.04      Running
1        started  10.5.15.239  juju-3e1944-1  ubuntu@22.04      Running
2        started  10.5.15.133  juju-3e1944-2  ubuntu@22.04      Running

09:46:34 INFO Juju error logs:

machine-0: 08:57:01 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 08:57:01 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-mongodb-0: 08:57:01 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-2: 08:57:08 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 08:57:08 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-test-qh11xhus-0: 08:57:08 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-mongodb-0: 08:57:37 ERROR unit.mongodb/0.juju-log Unable to set params: ['vm.max_map_count']
unit-mongodb-0: 08:57:37 ERROR unit.mongodb/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
machine-1: 08:58:00 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 08:58:00 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-github-runner-image-builder-qh11xhus-0: 08:58:00 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-test-qh11xhus-0: 08:58:20 ERROR unit.test-qh11xhus/0.juju-log Missing image integration.
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-test-qh11xhus-0/charm/./src/charm.py", line 118, in func_with_catch_errors
    func(self, event)
  File "/var/lib/juju/agents/unit-test-qh11xhus-0/charm/./src/charm.py", line 342, in _on_config_changed
    self._check_image_ready()
  File "/var/lib/juju/agents/unit-test-qh11xhus-0/charm/./src/charm.py", line 512, in _check_image_ready
    raise ImageIntegrationMissingError("No image integration found")
errors.ImageIntegrationMissingError: No image integration found
unit-test-qh11xhus-0: 08:58:22 ERROR unit.test-qh11xhus/0.juju-log Missing image integration.
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-test-qh11xhus-0/charm/./src/charm.py", line 118, in func_with_catch_errors
    func(self, event)
  File "/var/lib/juju/agents/unit-test-qh11xhus-0/charm/./src/charm.py", line 313, in _on_start
    self._check_image_ready()
  File "/var/lib/juju/agents/unit-test-qh11xhus-0/charm/./src/charm.py", line 512, in _check_image_ready
    raise ImageIntegrationMissingError("No image integration found")
errors.ImageIntegrationMissingError: No image integration found
unit-github-runner-image-builder-qh11xhus-0: 08:58:38 ERROR unit.github-runner-image-builder-qh11xhus/0.juju-log Pipx command failed, code: 1, out: None, err: None
unit-test-qh11xhus-0: 09:00:51 ERROR unit.test-qh11xhus/0.juju-log image:4: Missing image in image integration.
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-test-qh11xhus-0/charm/./src/charm.py", line 118, in func_with_catch_errors
    func(self, event)
  File "/var/lib/juju/agents/unit-test-qh11xhus-0/charm/./src/charm.py", line 477, in _on_image_relation_changed
    self._check_image_ready()
  File "/var/lib/juju/agents/unit-test-qh11xhus-0/charm/./src/charm.py", line 514, in _check_image_ready
    raise ImageNotFoundError("No image found in the image integration")
errors.ImageNotFoundError: No image found in the image integration

09:46:34 INFO Forgetting model main...